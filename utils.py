"""
ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ç”»é¢è¡¨ç¤ºä»¥å¤–ã®æ§˜ã€…ãªé–¢æ•°å®šç¾©ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚
"""

############################################################
# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
############################################################

import os
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
import constants as ct

def handle_user_input(user_input):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å‡¦ç†ã—ã¦AIå›ç­”ã‚’ç”Ÿæˆ
    """
    import streamlit as st
    
    # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if not hasattr(st.session_state, 'vectorstore') or st.session_state.vectorstore is None:
        return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¦ã„ãªã„ãŸã‚ã€æ¤œç´¢æ©Ÿèƒ½ã‚’åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚OpenAI APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ã”ç¢ºèªãã ã•ã„ã€‚"
    
    try:
        vectorstore = st.session_state.vectorstore
        retriever = vectorstore.as_retriever(search_kwargs={"k": ct.RETRIEVER_TOP_K})

        # ãƒ€ãƒŸãƒ¼ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã®å ´åˆã¯ç°¡å˜ãªå¿œç­”ã‚’è¿”ã™
        if hasattr(st.session_state.vectorstore, '__class__') and 'Dummy' in st.session_state.vectorstore.__class__.__name__:
            results = retriever.get_relevant_documents(user_input)
            
            answer_text = "### ğŸ” æ¤œç´¢çµæœï¼ˆãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼‰\n\n"
            answer_text += "**å‚ç…§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:**\n"
            for idx, doc in enumerate(results, 1):
                source = doc.metadata.get("source", "ä¸æ˜ãªã‚½ãƒ¼ã‚¹")
                page = doc.metadata.get("page", None)
                chunk = doc.metadata.get("chunk", None)
                
                if source.endswith(".pdf"):
                    if page is not None:
                        answer_text += f"{idx}. ğŸ“„ **{os.path.basename(source)}** - {page + 1}ãƒšãƒ¼ã‚¸ç›®\n"
                    else:
                        answer_text += f"{idx}. ğŸ“„ **{os.path.basename(source)}**\n"
                elif chunk is not None:
                    answer_text += f"{idx}. ğŸ“„ **{os.path.basename(source)}** - ã‚»ã‚¯ã‚·ãƒ§ãƒ³{chunk + 1}\n"
                else:
                    answer_text += f"{idx}. ğŸ“„ **{os.path.basename(source)}**\n"
            
            answer_text += "\n---\n"
            answer_text += f"**ãƒ†ã‚¹ãƒˆå¿œç­”:** \nå…¥åŠ›å†…å®¹ã€Œ{user_input}ã€ã‚’å—ã‘å–ã‚Šã¾ã—ãŸã€‚\n"
            answer_text += "å®Ÿéš›ã®OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã™ã‚‹ã¨ã€æœ¬æ ¼çš„ãªAIæ¤œç´¢æ©Ÿèƒ½ã‚’åˆ©ç”¨ã§ãã¾ã™ã€‚\n"
            answer_text += "ç¾åœ¨ã¯ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¦ã„ã¾ã™ã€‚"
            
            return answer_text
        
        # å®Ÿéš›ã®ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã®å ´åˆ
        llm = ChatOpenAI(temperature=0)
        qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)

        results = retriever.get_relevant_documents(user_input)

        answer_text = "### ğŸ” å‚ç…§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ\n\n"
        for idx, doc in enumerate(results, 1):
            source = doc.metadata.get("source", "ä¸æ˜ãªã‚½ãƒ¼ã‚¹")
            page = doc.metadata.get("page", None)
            chunk = doc.metadata.get("chunk", None)

            if source.endswith(".pdf"):
                if page is not None:
                    answer_text += f"{idx}. ğŸ“„ **{os.path.basename(source)}** - {page + 1}ãƒšãƒ¼ã‚¸ç›®\n"
                else:
                    answer_text += f"{idx}. ğŸ“„ **{os.path.basename(source)}**\n"
            elif source.endswith(".docx"):
                if chunk is not None:
                    answer_text += f"{idx}. ğŸ“„ **{os.path.basename(source)}** - ã‚»ã‚¯ã‚·ãƒ§ãƒ³{chunk + 1}\n"
                else:
                    answer_text += f"{idx}. ğŸ“„ **{os.path.basename(source)}**\n"
            elif source.endswith(".csv"):
                if chunk is not None:
                    answer_text += f"{idx}. ğŸ“Š **{os.path.basename(source)}** - ãƒ‡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³{chunk + 1}\n"
                else:
                    answer_text += f"{idx}. ğŸ“Š **{os.path.basename(source)}**\n"
            elif source.endswith(".txt"):
                if chunk is not None:
                    answer_text += f"{idx}. ğŸ“ **{os.path.basename(source)}** - ã‚»ã‚¯ã‚·ãƒ§ãƒ³{chunk + 1}\n"
                else:
                    answer_text += f"{idx}. ï¿½ **{os.path.basename(source)}**\n"
            else:
                answer_text += f"{idx}. ğŸ“„ **{os.path.basename(source)}**\n"

        answer_text += "\n---\n"

        # LLMå›ç­”
        response = qa_chain.run(user_input)
        answer_text += f"**AIå›ç­”:**\n{response}"

        return answer_text
        
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"


def get_error_message():
    """
    ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™é–¢æ•°
    """
    return "åˆæœŸåŒ–å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚"
